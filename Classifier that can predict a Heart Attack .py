# -*- coding: utf-8 -*-
"""Day 46: Logistics Regression (Practical).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XARpp1k2IzX_VpUldqxndpV94PA_tYhM

# Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import math

"""# Problem Statement

You have been given a dataset that includes all the medical condition of a patient. You need to build a classifier that can predict how likely a patient can get a heart stroke.

# Importing the dataset

Link: https://drive.google.com/file/d/1uqi87nveAWf1sQ6bTaedVBEGidwre1Pf/view?usp=sharing
"""

df = pd.read_csv('/content/drive/MyDrive/ShapeAI DST 11021 Oct-Jan Batch 2021-22/Datasets/healthcare-dataset-stroke-data.csv')

"""# EDA - Exploratory Data Analysis (DE,DM,DC,DV)"""

df.head()

df.tail()

df.info()

df.describe()

df.describe().T

df.head(2)

# Remove the 'id' column
df.drop('id', axis=1, inplace=True)

df.head()

df.gender.nunique()

df.gender.unique()

df.gender.value_counts()

df.gender.value_counts().plot(kind='bar')

df.gender.replace('Other', 'Female', inplace=True)

df.gender.value_counts()

le = LabelEncoder()

le.fit_transform(df.gender)

df.head()

df.gender = le.fit_transform(df.gender)

df.head()

# Show me the datapoint(s) where Age == 0.08
df[df.age == 0.08]

# Provide all the datatpoints where work_type = 'children'
df[df.work_type == "children"]

0.08 -> 8 Days
0

x >= 0.5 (Ceiling)
x < 0.5 (Floor)

# Where ever there will be 0, re-assign it as 1

1
1.x ->2

for i in range(len(df.age)):
  difference = df.age[i] - int(df.age[i])

  if difference >= 0.5:
    df.age[i] = math.ceil(df.age[i])
  else:
    df.age[i] = math.floor(df.age[i])

df.age[0]

df[df.work_type == "children"]

df[df.age==0]

df.age = df.age.astype('int')

df.age.replace(0,1, inplace=True)

df[df.age==0]

df.info()

df.hypertension

df.hypertension.value_counts()

# 80 -> Train & 20 -> Test
(5110 * 80)/100

df.heart_disease.value_counts()

df.ever_married.value_counts()

df.ever_married = le.fit_transform(df.ever_married)

df.head(2)

df.work_type.unique()

df.work_type.value_counts()

Working -> Private, Self-employed, Govt_job
Never_worked -> children, Never_worked

df.work_type.replace(['Private', 'Self-employed', 'Govt_job', 'children'],
                     ['Worked', 'Worked', 'Worked', 'Never_worked'], inplace=True)

df.work_type = le.fit_transform(df.work_type)

df.head()

df.Residence_type.unique()

df.Residence_type.value_counts()

df.Residence_type = le.fit_transform(df.Residence_type)

df.bmi.isnull().sum()

# Mean
df.bmi.mean()

# Median
df.bmi.median()

# Mode
df.bmi.mode()

df.bmi.fillna(df.bmi.mean(), inplace=True)

df.head(2)

df.smoking_status.unique()

df.smoking_status.value_counts()

df.head()

# Show the smoking_status of all the patients where work_type is 'children'
df.loc[df.work_type=='children', ['work_type','smoking_status']]

df.loc[df.work_type=='children', ['smoking_status']] = df.loc[df.work_type == 'children', ['smoking_status']].replace('Unknown', 'never_smoked')

df.loc[df.work_type=='children', ['work_type','smoking_status']]

df.smoking_status.value_counts()

df.smoking_status.replace('never smoked', 'never_smoked', inplace=True)

df.smoking_status.replace('formerly smoked', 'formerly_smoked', inplace=True)

df.smoking_status.value_counts()

newdf = df.copy()

ohe = OneHotEncoder(sparse=False)

newcol = ohe.fit_transform(df[['smoking_status']])

newcol

'Unknown', 'formerly_smoked', 'never_smoked', 'smokes'

df.smoking_status

df[['Unknown', 'formerly_smoked', 'never_smoked', 'smokes']] = newcol

df.head()

df.drop(['smoking_status', 'smokes'], axis=1, inplace=True)

df.head()

df.info()

df.corr()

plt.figure(figsize=(50,50))
sns.heatmap(df.corr(), annot=True, cmap="Greens")

"""# Model Selection"""

lr_classifier = LogisticRegression()
dt_classifier = DecisionTreeClassifier()
rf_classifier = RandomForestClassifier()

"""# Splitting the Dataset"""

X = df.drop('stroke', axis=1)
y = df.stroke

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Training the model"""

lr_classifier.fit(X_train, y_train)
dt_classifier.fit(X_train, y_train)
rf_classifier.fit(X_train, y_train)

"""# Testing the model"""

lr_y_pred = lr_classifier.predict(X_test)
dt_y_pred = dt_classifier.predict(X_test)
rf_y_pred = rf_classifier.predict(X_test)

final = pd.DataFrame({"Actual": y_test,
                      "Logistic_Regression": lr_y_pred,
                      "Decision_Tree": dt_y_pred,
                      "Random_Forest": rf_y_pred})

final

final.corr()

"""# Performance Checking - Confusion Matrix"""

confusion_matrix(y_test, lr_y_pred)

accuracy = (960 + 0)/ Total (960 + 0 + 62 + 0)

(960 + 0)/(960 + 0 + 62 + 0) = 0.939 = 0.94 = 94%

confusion_matrix(y_test, dt_y_pred)

(922 + 8)/(922 + 38 + 54 + 8) = 0.909 = 0.91 = 91%

confusion_matrix(y_test, rf_y_pred)

(959 + 1)/(959+1+61+1) = 0.939 = 0.94 = 94%

classification_report(y_test, lr_y_pred)